{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GPT-2 Model",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "KBkpRgBCBS2_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%tensorflow_version 1.x\n",
        "!pip install -q gpt-2-simple\n",
        "import gpt_2_simple as gpt2\n",
        "from datetime import datetime\n",
        "from google.colab import files"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P8wSlgXoDPCR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# model sizes : 124M, 355M, 774M, 1558M\n",
        "# only the first two models can be finetuned\n",
        "\n",
        "gpt2.download_gpt2(model_name=\"124M\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "puq4iC6vUAHc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Mount google drive to store trained model in drive later\n",
        "gpt2.mount_gdrive()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6OFnPCLADfll",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "file_name = \"processed_texts_1000.csv\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Z6okFD8VKtS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "gpt2.copy_file_from_gdrive(file_name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aeXshJM-Cuaf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "b8e2b1c9-7e22-455d-f9b0-d28d240b635a"
      },
      "source": [
        "sess = gpt2.start_tf_sess()\n",
        "\n",
        "gpt2.finetune(sess,\n",
        "              dataset=file_name,\n",
        "              model_name='124M',\n",
        "              steps=1000,\n",
        "              restore_from='fresh',\n",
        "              run_name='run1',\n",
        "              print_every=10,\n",
        "              sample_every=200,\n",
        "              save_every=500\n",
        "              )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/gpt_2_simple/src/sample.py:17: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "Loading checkpoint models/124M/model.ckpt\n",
            "INFO:tensorflow:Restoring parameters from models/124M/model.ckpt\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00,  7.76it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loading dataset...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "dataset has 17667 tokens\n",
            "Training...\n",
            "[10 | 51.52] loss=1.84 avg=1.84\n",
            "[20 | 95.02] loss=1.47 avg=1.65\n",
            "[30 | 138.89] loss=1.18 avg=1.49\n",
            "[40 | 182.78] loss=0.88 avg=1.34\n",
            "[50 | 226.72] loss=0.50 avg=1.17\n",
            "[60 | 270.69] loss=0.35 avg=1.03\n",
            "[70 | 314.63] loss=0.20 avg=0.91\n",
            "[80 | 358.51] loss=0.16 avg=0.81\n",
            "[90 | 402.45] loss=0.10 avg=0.73\n",
            "[100 | 446.36] loss=0.06 avg=0.66\n",
            "[110 | 490.29] loss=0.06 avg=0.60\n",
            "[120 | 534.23] loss=0.03 avg=0.55\n",
            "[130 | 578.18] loss=0.02 avg=0.51\n",
            "[140 | 622.11] loss=0.03 avg=0.47\n",
            "[150 | 666.04] loss=0.02 avg=0.44\n",
            "[160 | 709.98] loss=0.02 avg=0.41\n",
            "[170 | 753.88] loss=0.02 avg=0.39\n",
            "[180 | 797.83] loss=0.03 avg=0.36\n",
            "[190 | 841.76] loss=0.02 avg=0.35\n",
            "[200 | 885.67] loss=0.01 avg=0.33\n",
            "======== SAMPLE 1 ========\n",
            " my talks<|endoftext|>\n",
            "<|startoftext|>I think I was supposed to talk about my new book<|endoftext|>\n",
            "<|startoftext|>When you have 21 minutes to speak<|endoftext|>\n",
            "<|startoftext|>I'm going to talk to you about some stuff that's in this book of mine that I hope will resonate with other things you've already heard<|endoftext|>\n",
            "<|startoftext|>Thank you. It's really an honor and a privilege to be here spending my last day as a teenager. Today I want to talk to you about the future<|endoftext|>\n",
            "<|startoftext|>18 minutes is an absolutely brutal time limit<|endoftext|>\n",
            "<|startoftext|>I'll just take you to Bangladesh for a minute.Before I tell that story<|endoftext|>\n",
            "<|startoftext|>I want to start with a story<|endoftext|>\n",
            "<|startoftext|>Video: Narrator: An event seen from one point of view gives one impression. Seen from another point of view<|endoftext|>\n",
            "<|startoftext|>A public<|endoftext|>\n",
            "<|startoftext|>I want to start off by saying<|endoftext|>\n",
            "<|startoftext|>This is me. My name is Ben Saunders. I'm a serial entrepreneur turned serial investor. In this series<|endoftext|>\n",
            "<|startoftext|>I ’d like to dedicate this one to all the women in South Africa — those women who refused to dwindle in the midst of apartheid. And<|endoftext|>\n",
            "<|startoftext|>I've actually been waiting by the phone for a call from TED for years. And in fact<|endoftext|>\n",
            "<|startoftext|>I got a visit almost exactly a year ago<|endoftext|>\n",
            "<|startoftext|>Now<|endoftext|>\n",
            "<|startoftext|>I am very<|endoftext|>\n",
            "<|startoftext|>I would like to tell you about a project which I started about 16 years ago. It's about making new forms of life. And these are made of this kind of tube — electricity tube<|endoftext|>\n",
            "<|startoftext|>This is a picture of Maurice Druon<|endoftext|>\n",
            "<|startoftext|>Images like this<|endoftext|>\n",
            "<|startoftext|>Three years ago<|endoftext|>\n",
            "<|startoftext|>I have 18 minutes to tell you what happened between now and now. All right. We all have come from great nations. We all have come from great nations. When I was President of the Academy of Arts and Sciences<|endoftext|>\n",
            "<|startoftext|>The future of life<|endoftext|>\n",
            "<|startoftext|>What's happening in the computer-generated worlds<|endoftext|>\n",
            "<|startoftext|>I’d like to dedicate this one to all the women in South Africa — those women who refused to dwindle in the midst of apartheid. And in fact<|endoftext|>\n",
            "<|startoftext|>Believe me or not<|endoftext|>\n",
            "<|startoftext|>I've actually been away from the lab for a few days. I thought I'd talk about the experiments I went to university with because I got invited. I didn't go to university trying to understand the brain activity of animals. I came to the lab to see whether I could create a living organism that would be capable of replicating what it does. When I walked in the door<|endoftext|>\n",
            "<|startoftext|>It's a simple idea about nature. I want to say a word for nature because we haven't talked that much about it the last couple days. I want to say a word for the soil and the bees and the plants and the animals<|endoftext|>\n",
            "<|startoftext|>I'm here to enlist you in helping reshape the story about how humans and other critters get things done. Here is the old story — we've already heard a little bit about it: biology is war in which only the fiercest survive; businesses and nations succeed only by defeating<|endoftext|>\n",
            "<|startoftext|>What I wanted to talk to you about today is two things: one<|endoftext|>\n",
            "<|startoftext|>What\n",
            "\n",
            "[210 | 948.08] loss=0.03 avg=0.31\n",
            "[220 | 992.05] loss=0.02 avg=0.30\n",
            "[230 | 1036.06] loss=0.02 avg=0.28\n",
            "[240 | 1080.05] loss=0.02 avg=0.27\n",
            "[250 | 1124.02] loss=0.02 avg=0.26\n",
            "[260 | 1167.99] loss=0.02 avg=0.25\n",
            "[270 | 1211.96] loss=0.02 avg=0.24\n",
            "[280 | 1255.89] loss=0.03 avg=0.23\n",
            "[290 | 1299.84] loss=0.02 avg=0.22\n",
            "[300 | 1343.80] loss=0.02 avg=0.21\n",
            "[310 | 1387.71] loss=0.02 avg=0.21\n",
            "[320 | 1431.62] loss=0.02 avg=0.20\n",
            "[330 | 1475.52] loss=0.01 avg=0.19\n",
            "[340 | 1519.47] loss=0.01 avg=0.19\n",
            "[350 | 1563.46] loss=0.02 avg=0.18\n",
            "[360 | 1607.45] loss=0.02 avg=0.18\n",
            "[370 | 1651.39] loss=0.02 avg=0.17\n",
            "[380 | 1695.32] loss=0.02 avg=0.17\n",
            "[390 | 1739.22] loss=0.02 avg=0.16\n",
            "[400 | 1783.17] loss=0.02 avg=0.16\n",
            "======== SAMPLE 1 ========\n",
            " the first question. There is a great deal of work to be done in terms of biology and design and everything in between. But the work that I am mostly obsessed with is the design of places. And I'm particularly interested in the design of cities. I live in a little town and a big city. So I'm pretty into stuff like that. But I'm also pretty into stuff like airplane motorways. So I'm for the airplane motorway. I think it's one of those things that's just… (Applause)<|endoftext|>\n",
            "<|startoftext|>There's an ancient and universal concept that words have power<|endoftext|>\n",
            "<|startoftext|>You've all seen lots of articles on climate change<|endoftext|>\n",
            "<|startoftext|>What is bioenergy? Bioenergy is not ethanol. Bioenergy isn't global warming. Bioenergy is something which seems counterintuitive. Bioenergy is oil. It's gas. It's coal. And part of building that bridge to the future<|endoftext|>\n",
            "<|startoftext|>I'm going to try to give you a view of the world as I see it<|endoftext|>\n",
            "<|startoftext|>I want you to imagine<|endoftext|>\n",
            "<|startoftext|>I want to see a frog<|endoftext|>\n",
            "<|startoftext|>How will we be remembered in 200 years? I happen to live in a little town<|endoftext|>\n",
            "<|startoftext|>I and my colleagues Art Aron and Lucy Brown and others<|endoftext|>\n",
            "<|startoftext|>As a clergyman<|endoftext|>\n",
            "<|startoftext|>I thought I'd tell you a little about what I like to write. And I like to immerse myself in my topics. I just like to dive right in and become sort of a human guinea pig. And I see my life as a series of experiments.So<|endoftext|>\n",
            "<|startoftext|>Brain magic. What's brain magic all about? Brain magic to me indicates that area of magic dealing with psychological and mind-reading effects. So unlike traditional magic<|endoftext|>\n",
            "<|startoftext|>When I was President of the American Psychological Association<|endoftext|>\n",
            "<|startoftext|>The decorative use of wire in southern Africa dates back hundreds of years. But modernization actually brought communication and a much broader range of uses<|endoftext|>\n",
            "<|startoftext|>My search is always to find ways to chronicle<|endoftext|>\n",
            "<|startoftext|>Who are we? That is the big question. And essentially we are just an upright-walking<|endoftext|>\n",
            "<|startoftext|>So I'm going to talk today about collecting stories in some unconventional ways. This is a picture of me from a very awkward stage in my life. You might enjoy the awkwardly tight<|endoftext|>\n",
            "<|startoftext|>To be new at TED — it's like being the last high-school virgin. (Laughter) You know that all of the cool people are — they're doing it. And you're on the outside<|endoftext|>\n",
            "<|startoftext|>The Internet<|endoftext|>\n",
            "<|startoftext|>I got my first computer when I was a teenager growing up in Accra<|endoftext|>\n",
            "<|startoftext|>My talk is \"\"Flapping Birds and Space Telescopes.\"\" And you would think that should have nothing to do with one another<|endoftext|>\n",
            "<|startoftext|>Hello everyone. And so the two of us are here to give you an example of creation. And I'm going to be folding one of Robert Lang's models. And this is the piece of paper it will be made from<|endoftext|>\n",
            "<|startoftext|>As a particle physicist<|endoftext|>\n",
            "<|startoftext|>Jambo<|endoftext|>\n",
            "<|startoftext|>Let's just start by looking at some great photographs. This is an icon of National Geographic<|endoftext|>\n",
            "<|startoftext|>My favorite topic is shortcuts. The master of shortcuts — it's<|endoftext|>\n",
            "<|startoftext|>Dogs have interests. They have interest sniffing each other<|endoftext|>\n",
            "<|startoftext|>I’d like to dedicate this next song to Carmelo\n",
            "\n",
            "[410 | 1844.15] loss=0.02 avg=0.15\n",
            "[420 | 1888.13] loss=0.01 avg=0.15\n",
            "[430 | 1932.31] loss=0.02 avg=0.15\n",
            "[440 | 1976.55] loss=0.01 avg=0.14\n",
            "[450 | 2020.77] loss=0.01 avg=0.14\n",
            "[460 | 2064.94] loss=0.01 avg=0.14\n",
            "[470 | 2109.15] loss=0.02 avg=0.13\n",
            "[480 | 2153.38] loss=0.01 avg=0.13\n",
            "[490 | 2197.59] loss=0.01 avg=0.13\n",
            "[500 | 2241.65] loss=0.02 avg=0.12\n",
            "Saving checkpoint/run1/model-500\n",
            "[510 | 2289.06] loss=0.02 avg=0.12\n",
            "[520 | 2333.28] loss=0.04 avg=0.12\n",
            "[530 | 2377.48] loss=0.01 avg=0.12\n",
            "[540 | 2421.71] loss=0.01 avg=0.11\n",
            "[550 | 2465.89] loss=0.01 avg=0.11\n",
            "[560 | 2510.11] loss=0.02 avg=0.11\n",
            "[570 | 2554.33] loss=0.02 avg=0.11\n",
            "[580 | 2598.55] loss=0.01 avg=0.10\n",
            "[590 | 2642.76] loss=0.01 avg=0.10\n",
            "[600 | 2687.00] loss=0.01 avg=0.10\n",
            "======== SAMPLE 1 ========\n",
            "<|startoftext|>This machine<|endoftext|>\n",
            "<|startoftext|>I should tell you that when I was U.S. ambassador to Switzerland<|endoftext|>\n",
            "<|startoftext|>We are going to talk today about the revolution in rejuvenated engines. Powered by two Caterham F1000 engines<|endoftext|>\n",
            "<|startoftext|>I grew up in Europe<|endoftext|>\n",
            "<|startoftext|>So<|endoftext|>\n",
            "<|startoftext|>I want to take you back basically to my hometown<|endoftext|>\n",
            "<|startoftext|>Let's just get started here.Okay<|endoftext|>\n",
            "<|startoftext|>Whoa<|endoftext|>\n",
            "<|startoftext|>I dabble in design. I'm a curator of architecture and design; I happen to be at the Museum of Modern Art. But what we're going to talk about today is really design. Really good designers are like sponges: they really are curious and absorb every kind of information that comes their way<|endoftext|>\n",
            "<|startoftext|>You might be wondering why I'm wearing sunglasses<|endoftext|>\n",
            "<|startoftext|>This session is on natural wonders<|endoftext|>\n",
            "<|startoftext|>You all know this story. In the summer of 1950<|endoftext|>\n",
            "<|startoftext|>You hear that this is the era of environment — or biology<|endoftext|>\n",
            "<|startoftext|>I grew up in Europe<|endoftext|>\n",
            "<|startoftext|>When I first arrived in beautiful Zimbabwe<|endoftext|>\n",
            "<|startoftext|>I think all of us have been interested<|endoftext|>\n",
            "<|startoftext|>This means<|endoftext|>\n",
            "<|startoftext|>Zach Kaplan: Keith and I lead a research team. We investigate materials and technologies that have unexpected properties. Over the last three years<|endoftext|>\n",
            "<|startoftext|>This is very strange for me<|endoftext|>\n",
            "<|startoftext|>One of my favorite cartoon characters is Snoopy. I love the way he sits and lies on his kennel and contemplates the great things of life. So when I thought about compassion<|endoftext|>\n",
            "<|startoftext|>A human child is born<|endoftext|>\n",
            "<|startoftext|>Compassion: what does it look like? Come with me to 915 South Bloodworth Street in Raleigh<|endoftext|>\n",
            "<|startoftext|>I'm speaking about compassion from an Islamic point of view<|endoftext|>\n",
            "<|startoftext|>I want to open by quoting Einstein's wonderful statement<|endoftext|>\n",
            "<|startoftext|>I'm going to talk about compassion and the golden rule from a secular perspective and even from a kind of scientific perspective. I'm going to try to give you a little bit of a natural history of compassion and the golden rule. So<|endoftext|>\n",
            "<|startoftext|>I think the future of this planet depends on humans<|endoftext|>\n",
            "<|startoftext|>This was in an area called Wellawatta<|endoftext|>\n",
            "<|startoftext|>(Music)(Applause)Thank you for being here. And I say \"\"thank you for being here\"\" because I was silent for 17 years. And the first words that I spoke were in Washington<|endoftext|>\n",
            "<|startoftext|>This is a guy named Bob McKim. He was a creativity researcher in the '60s and '70s<|endoftext|>\n",
            "<|startoftext|>The fragrance that you will smell<|endoftext|>\n",
            "<|startoftext|>So<|endoftext|>\n",
            "<|startoftext|>I spent the better part of a decade looking at American responses to mass atrocity and genocide. And I'd like to start by sharing with you one moment that to me sums up what there is to know about American and democratic responses to mass atrocity.And that moment came on April 21<|endoftext|>\n",
            "<|startoftext|>I thought I'd start with telling you or showing you the people who started [Jet Propulsion Lab]. When they were a bunch of kids<|endoftext|>\n",
            "<|\n",
            "\n",
            "[610 | 2748.38] loss=0.01 avg=0.10\n",
            "[620 | 2792.60] loss=0.02 avg=0.10\n",
            "[630 | 2836.81] loss=0.01 avg=0.10\n",
            "[640 | 2881.01] loss=0.01 avg=0.09\n",
            "[650 | 2925.22] loss=0.01 avg=0.09\n",
            "[660 | 2969.40] loss=0.02 avg=0.09\n",
            "[670 | 3013.57] loss=0.01 avg=0.09\n",
            "[680 | 3057.75] loss=0.01 avg=0.09\n",
            "[690 | 3101.92] loss=0.02 avg=0.09\n",
            "[700 | 3146.10] loss=0.01 avg=0.08\n",
            "[710 | 3190.32] loss=0.01 avg=0.08\n",
            "[720 | 3234.52] loss=0.02 avg=0.08\n",
            "[730 | 3278.75] loss=0.01 avg=0.08\n",
            "[740 | 3322.93] loss=0.01 avg=0.08\n",
            "[750 | 3367.13] loss=0.01 avg=0.08\n",
            "[760 | 3411.37] loss=0.01 avg=0.08\n",
            "[770 | 3455.56] loss=0.01 avg=0.08\n",
            "[780 | 3499.79] loss=0.02 avg=0.07\n",
            "[790 | 3544.02] loss=0.01 avg=0.07\n",
            "[800 | 3588.22] loss=0.01 avg=0.07\n",
            "======== SAMPLE 1 ========\n",
            "text|>\n",
            "<|startoftext|>Good morning everyone. First of all<|endoftext|>\n",
            "<|startoftext|>I'm going to give you four specific examples<|endoftext|>\n",
            "<|startoftext|>Well<|endoftext|>\n",
            "<|startoftext|>We're going to talk — my — a new lecture<|endoftext|>\n",
            "<|startoftext|>As you pointed out<|endoftext|>\n",
            "<|startoftext|>I'm supposed to scare you<|endoftext|>\n",
            "<|startoftext|>About 15 years ago<|endoftext|>\n",
            "<|startoftext|>When I'm starting talks like this<|endoftext|>\n",
            "<|startoftext|>I don't know your name. Audience Member: Howard. Howard.Thom Mayne: Howard? I'm sitting next to Howard. I don't know Howard<|endoftext|>\n",
            "<|startoftext|>What I want to talk about is<|endoftext|>\n",
            "<|startoftext|>I'd like to begin this song I wrote about ceaseless yearning and never-ending want with a poem of popular Petrarchan paradoxes by Sir Thomas Wyatt the Elder: \"\"I find no peace<|endoftext|>\n",
            "<|startoftext|>Hello. Actually<|endoftext|>\n",
            "<|startoftext|>I was asked to come here and speak about creation. And I only have 15 minutes<|endoftext|>\n",
            "<|startoftext|>I want to talk today about — I've been asked to take the long view<|endoftext|>\n",
            "<|startoftext|>It is a thrill to be here at a conference that's devoted to \"\"Inspired by Nature\"\" — you can imagine. And I'm also thrilled to be in the foreplay section. Did you notice this section is foreplay? Because I get to talk about one of my favorite critters<|endoftext|>\n",
            "<|startoftext|>At the break<|endoftext|>\n",
            "<|startoftext|>Imagine spending seven years at MIT and research laboratories<|endoftext|>\n",
            "<|startoftext|>I work with a species called \"\"Bonobo.\"\" And I'm happy most of the time<|endoftext|>\n",
            "<|startoftext|>Nature's my muse and it's been my passion. As a photographer for National Geographic<|endoftext|>\n",
            "<|startoftext|>If you'd like to learn how to play the lobster<|endoftext|>\n",
            "<|startoftext|>Okay.♫ Strolling along in Central Park ♫♫ Everyone's out today ♫♫ The daisies and dogwoods are all in bloom ♫♫ Oh<|endoftext|>\n",
            "<|startoftext|>Thank you very much. Now<|endoftext|>\n",
            "<|startoftext|>So I'm going to speak about a problem that I have and that's that I'm a philosopher.(Laughter)When I go to a party and people ask me what do I do and I say<|endoftext|>\n",
            "<|startoftext|>I'm not quite sure whether I really want to see a snare drum at nine o'clock or so in the morning.(Laughter)But anyway<|endoftext|>\n",
            "<|startoftext|>In 1962<|endoftext|>\n",
            "<|startoftext|>When you think about resilience and technology it's actually much easier. You're going to see some other speakers today<|endoftext|>\n",
            "<|startoftext|>Mockingbirds are badass.(Laughter) They are. Mockingbirds — that's Mimus polyglottos — are the emcees of the animal kingdom.They listen and mimic and remix what they like. They rock the mic outside my window every morning. I can hear them sing the sounds of the car alarms like they were songs of spring. I mean<|endoftext|>\n",
            "<|startoftext|>This is about a place in London called Kiteflyer's Hill where I used to go and spend hours going \"\"When is he coming back? When is he coming back?\"\" So this is another one dedicated to that guy ... who I've got over. But this is \"\"Kiteflyer's Hill.\"\" It's a beautiful song written by a guy called Martin Evan<|endoftext|>\n",
            "<|startoftext|>This song is one of Thomas' favorites<|endoftext|>\n",
            "<|\n",
            "\n",
            "[810 | 3649.59] loss=0.02 avg=0.07\n",
            "[820 | 3693.83] loss=0.02 avg=0.07\n",
            "[830 | 3738.01] loss=0.01 avg=0.07\n",
            "[840 | 3782.23] loss=0.01 avg=0.07\n",
            "[850 | 3826.44] loss=0.01 avg=0.07\n",
            "[860 | 3870.65] loss=0.01 avg=0.07\n",
            "[870 | 3914.84] loss=0.01 avg=0.06\n",
            "[880 | 3959.06] loss=0.02 avg=0.06\n",
            "[890 | 4003.30] loss=0.01 avg=0.06\n",
            "[900 | 4047.46] loss=0.01 avg=0.06\n",
            "[910 | 4091.62] loss=0.01 avg=0.06\n",
            "[920 | 4135.80] loss=0.01 avg=0.06\n",
            "[930 | 4179.98] loss=0.01 avg=0.06\n",
            "[940 | 4224.19] loss=0.02 avg=0.06\n",
            "[950 | 4268.40] loss=0.01 avg=0.06\n",
            "[960 | 4312.63] loss=0.01 avg=0.06\n",
            "[970 | 4356.86] loss=0.01 avg=0.06\n",
            "[980 | 4401.07] loss=0.02 avg=0.06\n",
            "[990 | 4445.27] loss=0.01 avg=0.06\n",
            "[1000 | 4489.49] loss=0.01 avg=0.06\n",
            "Saving checkpoint/run1/model-1000\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/training/saver.py:963: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to delete files with this prefix.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VHdTL8NDbAh3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Copy checkpoint folder to google drive\n",
        "gpt2.copy_checkpoint_to_gdrive(run_name='run1')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DCcx5u7sbPTD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load trained model checkpoint from google drive\n",
        "gpt2.copy_checkpoint_from_gdrive(run_name='run1')\n",
        "\n",
        "# load model\n",
        "sess = gpt2.start_tf_sess()\n",
        "gpt2.load_gpt2(sess, run_name='run1')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4RNY6RBI9LmL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 676
        },
        "outputId": "b42b97a9-71c2-4dd3-c68c-28afd7fad54c"
      },
      "source": [
        "# Generate text without prefix (Sentence beginning)\n",
        "gpt2.generate(sess, run_name='run1')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<|startoftext|>I'm going to talk about myself<|endoftext|>\n",
            "<|startoftext|>What I want to talk about is really scary. I'm going to talk about what I consider to be the world's deepest natural abyss. And I'm going to try to give you a little bit of a natural history of despair. A little bit of a mental history<|endoftext|>\n",
            "<|startoftext|>I think I was supposed to talk about my new book<|endoftext|>\n",
            "<|startoftext|>When you have 21 minutes to speak<|endoftext|>\n",
            "<|startoftext|>I'm going to talk to you about some stuff that's in this book of mine that I hope will resonate with other things you've already heard<|endoftext|>\n",
            "<|startoftext|>Thank you. It's really an honor and a privilege to be here spending my last day as a teenager. Today I want to talk to you about the future<|endoftext|>\n",
            "<|startoftext|>18 minutes is an absolutely brutal time limit<|endoftext|>\n",
            "<|startoftext|>I'll just take you to Bangladesh for a minute.Before I tell that story<|endoftext|>\n",
            "<|startoftext|>I want to start with a story<|endoftext|>\n",
            "<|startoftext|>Video: Narrator: An event seen from one point of view gives one impression. Seen from another point of view<|endoftext|>\n",
            "<|startoftext|>A public<|endoftext|>\n",
            "<|startoftext|>I want to start off by saying<|endoftext|>\n",
            "<|startoftext|>This is me. My name is Ben Saunders. I specialize in dragging heavy things around cold places.On May 11th last year<|endoftext|>\n",
            "<|startoftext|>Well<|endoftext|>\n",
            "<|startoftext|>Walk around for four months with three wishes<|endoftext|>\n",
            "<|startoftext|>I'm going to discuss with you three of my inventions that can have an effect on 10 to a 100 million people<|endoftext|>\n",
            "<|startoftext|>As other speakers have said<|endoftext|>\n",
            "<|startoftext|>I'm Michael Shermer<|endoftext|>\n",
            "<|startoftext|>Well<|endoftext|>\n",
            "<|startoftext|>I don't know about you<|endoftext|>\n",
            "<|startoftext|>I love trees<|endoftext|>\n",
            "<|startoftext|>This is really a two-hour presentation I give to high school students<|endoftext|>\n",
            "<|startoftext|>I wrote this poem after hearing a pretty well known actress tell a very well known interviewer on television<|endoftext|>\n",
            "<|startoftext|>With all the legitimate concerns about AIDS and avian flu — and we'll hear about that from the brilliant Dr. Brilliant later today — I want to talk about the other pandemic<|endoftext|>\n",
            "<|startoftext|>Let me show you some images of what I consider to be the cities of tomorrow. So<|endoftext|>\n",
            "<|startoftext|>What I'd like to talk about is really the biggest problems in the world. I'm not going to talk about \"\"The Skeptical Environmentalist\"\" — probably that's also a good choice. (Laughter)But I am going talk about: what are the big problems in the world? And I must say<|endoftext|>\n",
            "<|startoftext|>You know<|endoftext|>\n",
            "<|startoftext|>A fact came out of MIT<|endoftext|>\n",
            "<|startoftext|>If you take 10<|endoftext|>\n",
            "<|startoftext|>I've got apparently 18 minutes to convince you that history has a direction<|endoftext|>\n",
            "<|startoftext|>If you haven't ordered yet<|endoftext|>\n",
            "<|startoftext|>What I'm going to do<|endoftext|>\n",
            "<|startoftext|>So my grandfather told me when I was a little girl<|endoftext|>\n",
            "<|startoftext|>So anyway<|endoftext|>\n",
            "<|startoftext|>This meeting has really been about a digital revolution<|endoftext|>\n",
            "<|startoftext|\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8DKMc0fiej4N",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 194
        },
        "outputId": "db672f50-fae1-4dd1-98bd-219f19c7b4fd"
      },
      "source": [
        "# Generate text with prefix\n",
        "gpt2.generate(sess,\n",
        "              length=250,\n",
        "              temperature=0.7,\n",
        "              top_p=0.9,\n",
        "              prefix=\"Good evening everyone. My name \",\n",
        "              nsamples=5,\n",
        "              batch_size=5,\n",
        "              truncate='<|endoftext|>'\n",
        "              )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Good evening everyone. My name ۙکصاث and I only have one thing left to say\n",
            "====================\n",
            "Good evening everyone. My name ichthy is Malthus.HS.I in:HS.I in hast\n",
            "====================\n",
            "Good evening everyone. My name ichthy is up for auction today at 9:30 am. I'm selling shoes at thrift stores and online. And mostly I'm doing it\n",
            "====================\n",
            "Good evening everyone. My name ________ is Michael Shermer. I'm co-founder and senior columnist at Sheryl Shade. Shade is better known for its thanzac\n",
            "====================\n",
            "Good evening everyone. My name ersatzhan\n",
            "====================\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-xInIZKaU104",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 498
        },
        "outputId": "dd4a0070-85ff-4395-d695-4caf8d2bc188"
      },
      "source": [
        "# Generate Text from pretrained model (not finetuned)\n",
        "\n",
        "model_name = \"774M\"\n",
        "gpt2.download_gpt2(model_name=model_name)\n",
        "\n",
        "sess = gpt2.start_tf_sess()\n",
        "gpt2.load_gpt2(sess, model_name=model_name)\n",
        "\n",
        "gpt2.generate(sess,\n",
        "              model_name=model_name,\n",
        "              prefix=\"My research about\",\n",
        "              length=100,\n",
        "              temperature=0.7,\n",
        "              top_p=0.9,\n",
        "              nsamples=5,\n",
        "              batch_size=5\n",
        "              )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "My research about how to make the best of the weather in the city, and the urban planning of the city, has been very successful. We've had an incredible success in terms of people's trust in us and in the city.\n",
            "\n",
            "\"The success of the project has been enormous.\"\n",
            "\n",
            "Lennox said that the project is now a two-year project, which includes a \"sea change\" in the way the city is perceived.\n",
            "\n",
            "\"There's a new focus on sustainability and green\n",
            "====================\n",
            "My research about this site has been, and continues to be, very disappointing. I have to say that I am surprised by the level of misinformation about this site that I have found. The author of this site is not an expert on the subject matter and is not able to provide a clear and accurate explanation of the nature of the site. I do not know what he has been doing for the last four years, but he does not seem to have done any research into the subject matter.\n",
            "\n",
            "I have been\n",
            "====================\n",
            "My research about the history of the Baghpat-Burgay-Pundokoro Railway, which is known as the 'Pundokoro Railway', has led me to a major discovery. I have discovered that the Baghpat-Burgay-Pundokoro Railway was actually a part of the Kumasi-Burgay-Pundokoro Railway.\n",
            "\n",
            "The Kumasi-Burgay-Pundokoro Railway, which was constructed between 1864 and 1868\n",
            "====================\n",
            "My research about the history of the film industry reveals that the media's love affair with the idea of the \"great American movie\" dates back to the 1930s and 1940s. In the 1930s, the leading film studios were MGM, Universal, Warner Brothers, and Walt Disney. In the 1940s, the studios were Disney, Paramount, and Twentieth Century Fox. In the 1950s, the studios were the studios of Warner Brothers, Columbia, and MGM. In the 1960s, the studios were\n",
            "====================\n",
            "My research about the American public and politics found that Americans are very divided over whether they want to be involved in a government that works for them or one that works for big corporations.\n",
            "\n",
            "\"When I asked Americans about the most important issues facing the country today, they answered the economy, jobs, the deficit, education and health care.\n",
            "\n",
            "\"Americans are deeply divided over whether the government should work for them or for big business.\n",
            "\n",
            "\"The problem is that we have the wrong political system, and\n",
            "====================\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}